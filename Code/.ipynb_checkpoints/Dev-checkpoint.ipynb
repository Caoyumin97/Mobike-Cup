{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:38:23.749116Z",
     "start_time": "2020-02-23T05:38:23.745095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geohash import decode_exactly as dec_exa_fn,decode as dec_fn\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout\n",
    "from tensorflow.keras.initializers import he_normal,constant\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:23:42.358476Z",
     "start_time": "2020-02-23T05:23:39.551977Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:58:50.434210Z",
     "start_time": "2020-02-23T05:58:50.430186Z"
    }
   },
   "outputs": [],
   "source": [
    "def defix(x):\n",
    "    groups = re.match(\"w(.*)\",x)\n",
    "    if groups == None:\n",
    "        print(x)\n",
    "        return -1\n",
    "    elif len(groups[1]) == 6:\n",
    "        return groups[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:59:45.614687Z",
     "start_time": "2020-02-23T05:59:39.651664Z"
    }
   },
   "outputs": [],
   "source": [
    "data['starttime'] = pd.to_datetime(data['starttime'])\n",
    "data['defix_start'] = data['geohashed_start_loc'].map(lambda x:defix(x))\n",
    "data['defix_end'] = data['geohashed_end_loc'].map(lambda x:defix(x))\n",
    "data.drop(['geohashed_start_loc','geohashed_end_loc'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T05:59:46.861298Z",
     "start_time": "2020-02-23T05:59:46.851327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderid</th>\n",
       "      <th>userid</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>biketype</th>\n",
       "      <th>starttime</th>\n",
       "      <th>defix_start</th>\n",
       "      <th>defix_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1893973</td>\n",
       "      <td>451147</td>\n",
       "      <td>210617</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>x4snhx</td>\n",
       "      <td>x4snhj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4657992</td>\n",
       "      <td>1061133</td>\n",
       "      <td>465394</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:52</td>\n",
       "      <td>x4dr59</td>\n",
       "      <td>x4dquz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2965085</td>\n",
       "      <td>549189</td>\n",
       "      <td>310572</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>x4fgur</td>\n",
       "      <td>x4fu5n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4548579</td>\n",
       "      <td>489720</td>\n",
       "      <td>456688</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>x4d5r5</td>\n",
       "      <td>x4d5r4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3936364</td>\n",
       "      <td>467449</td>\n",
       "      <td>403224</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>x4g27p</td>\n",
       "      <td>x4g266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orderid   userid  bikeid  biketype           starttime defix_start  \\\n",
       "0  1893973   451147  210617         2 2017-05-14 22:16:50      x4snhx   \n",
       "1  4657992  1061133  465394         1 2017-05-14 22:16:52      x4dr59   \n",
       "2  2965085   549189  310572         1 2017-05-14 22:16:51      x4fgur   \n",
       "3  4548579   489720  456688         1 2017-05-14 22:16:51      x4d5r5   \n",
       "4  3936364   467449  403224         1 2017-05-14 22:16:50      x4g27p   \n",
       "\n",
       "  defix_end  \n",
       "0    x4snhj  \n",
       "1    x4dquz  \n",
       "2    x4fu5n  \n",
       "3    x4d5r4  \n",
       "4    x4g266  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T06:04:03.680135Z",
     "start_time": "2020-02-23T06:04:00.784678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orderID = Counter(data['orderid'])\n",
    "userID = Counter(data['userid'])\n",
    "bikeID = Counter(data['bikeid'])\n",
    "bikeType = Counter(data['biketype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T06:05:48.296555Z",
     "start_time": "2020-02-23T06:05:48.291569Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214096, 9, 6, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orderID),int(len(orderID)/len(userID)),int(len(orderID)/len(bikeID)),len(bikeType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T06:04:03.680135Z",
     "start_time": "2020-02-23T06:04:00.784678Z"
    }
   },
   "source": [
    "# Hashed Location Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T08:14:37.457675Z",
     "start_time": "2020-02-23T08:14:37.451692Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(col):\n",
    "    char_list = []\n",
    "    for ind,i in enumerate(data[col]):\n",
    "        char_list.append(list(i))\n",
    "\n",
    "    return char_list,list(np.unique(np.array(char_list)))\n",
    "\n",
    "def Vocabularizer(vocab_keys):\n",
    "    Vocab = {'token_to_idx':{},'idx_to_token':{}}\n",
    "    for ind, i in enumerate(vocab_keys):\n",
    "        Vocab['token_to_idx'][i] = ind\n",
    "        Vocab['idx_to_token'][ind] = i\n",
    "    return Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seq, vocab_keys = tokenizer('defix_start')\n",
    "end_seq, _ = tokenizer('defix_end')\n",
    "Vocab = Vocabularizer(vocab_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberizer(start_seq):\n",
    "    source_encoded = np.zeros_like(start_seq)\n",
    "    for idx_i, seq in enumerate(start_seq):\n",
    "        for idx_j, tk in enumerate(seq):\n",
    "            source_encoded[idx_i,idx_j] = Vocab['token_to_idx'][tk]\n",
    "    source_encoded = source_encoded.astype(int)\n",
    "    return source_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_encoded = numberizer(start_seq)\n",
    "target_encoded = numberizer(end_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3214096, 6), 3000000.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_encoded.shape,3e+6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = source_encoded[:int(3e+6)],target_encoded[:int(3e+6)]\n",
    "X_test,y_test = source_encoded[int(3e+6):],target_encoded[int(3e+6):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape = (6,))\n",
    "h = Dense(32,activation='relu',kernel_initializer=he_normal())(x)\n",
    "h = Dense(64,activation='relu',kernel_initializer=he_normal())(h)\n",
    "h = Dense(6,activation='relu',kernel_initializer=he_normal())(h)\n",
    "\n",
    "model = Model(inputs = x,outputs = h)\n",
    "model.compile(optimizer = 'adam',loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7053\n",
      "Epoch: 1, Accuracy: 2.98%\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7050\n",
      "Epoch: 2, Accuracy: 3.34%\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7047\n",
      "Epoch: 3, Accuracy: 3.84%\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7044\n",
      "Epoch: 4, Accuracy: 3.88%\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7043\n",
      "Epoch: 5, Accuracy: 3.46%\n",
      "3000000/3000000 [==============================] - 13s 4us/sample - loss: 1.7042\n",
      "Epoch: 6, Accuracy: 2.83%\n",
      "3000000/3000000 [==============================] - 14s 5us/sample - loss: 1.7039\n",
      "Epoch: 7, Accuracy: 3.48%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7038\n",
      "Epoch: 8, Accuracy: 3.90%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7037\n",
      "Epoch: 9, Accuracy: 4.28%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7037\n",
      "Epoch: 10, Accuracy: 5.19%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7036\n",
      "Epoch: 11, Accuracy: 4.30%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7034\n",
      "Epoch: 12, Accuracy: 2.54%\n",
      "3000000/3000000 [==============================] - 16s 5us/sample - loss: 1.7033\n",
      "Epoch: 13, Accuracy: 4.97%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7033\n",
      "Epoch: 14, Accuracy: 2.98%\n",
      "3000000/3000000 [==============================] - 16s 5us/sample - loss: 1.7032\n",
      "Epoch: 15, Accuracy: 5.39%\n",
      "3000000/3000000 [==============================] - 17s 6us/sample - loss: 1.7029\n",
      "Epoch: 16, Accuracy: 3.25%\n",
      "3000000/3000000 [==============================] - 16s 5us/sample - loss: 1.7029\n",
      "Epoch: 17, Accuracy: 2.94%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7027\n",
      "Epoch: 18, Accuracy: 5.34%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7026\n",
      "Epoch: 19, Accuracy: 3.43%\n",
      "3000000/3000000 [==============================] - 15s 5us/sample - loss: 1.7026\n",
      "Epoch: 20, Accuracy: 3.64%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    hist = model.fit(X_train,y_train,batch_size=256,epochs=1,verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    print('Epoch: %d, Accuracy: %.2f%%' %(epoch + 1,100 * Acc(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.64%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "print('Accuracy: %.2f%%' %(100 * Acc(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterizer(y_pred):\n",
    "    target_encoded = np.zeros_like(y_pred).astype(str)\n",
    "    for idx_i, seq in enumerate(list(y_pred)):\n",
    "        for idx_j, st in enumerate(seq):\n",
    "            target_encoded[idx_i,idx_j] = Vocab['idx_to_token'][st]\n",
    "    return target_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Acc(y_pred,y_test):\n",
    "    y_pred_char = characterizer(y_pred)\n",
    "    y_test_char = characterizer(y_test)\n",
    "    acc = (((y_test_char == y_pred_char).sum(axis = 1) - 6) >= 0).sum() / y_test.shape[0]\n",
    "    return acc"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
